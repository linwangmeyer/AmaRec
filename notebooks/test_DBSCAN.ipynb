{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify optiomal eps and min_samples values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "eps_values = [0.5, 1.0, 1.5]  # Example values for eps\n",
    "min_samples_values = [5, 10, 15]  # Example values for min_samples\n",
    "best_score = -1\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "progress_bar = tqdm(total=len(eps_values)*len(min_samples_values), desc='DBSCAN progress')\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(matrix.T)\n",
    "\n",
    "        # Exclude outliers (-1 label) from silhouette score calculation\n",
    "        if np.unique(labels) != -1:\n",
    "            if -1 in labels:\n",
    "                score = silhouette_score(matrix.T[labels != -1], labels[labels != -1])\n",
    "            else:\n",
    "                score = silhouette_score(matrix.T, labels)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_eps = eps\n",
    "            best_min_samples = min_samples\n",
    "        progress_bar.update(1)\n",
    "\n",
    "print(\"Best eps:\", best_eps)\n",
    "print(\"Best min_samples:\", best_min_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(matrix.T)\n",
    "\n",
    "score = silhouette_score(matrix.T, labels)\n",
    "print(f'silhouette value: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dblabel = pd.Series(labels,name='product cluster label')\n",
    "df_dbscan = pd.concat([unique_rows_series,df_dblabel], axis=1)\n",
    "df_dbscan.columns = ['product title', 'product cluster label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = df_dbscan['product cluster label'].unique()\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, cluster_label in enumerate(cluster_labels):\n",
    "    df_text = df_kmean[df_kmean['product cluster label'] == cluster_label]['product title']\n",
    "    combined_text = ' '.join(df_text)\n",
    "    word_frequencies = Counter(combined_text.split())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "    ax = axes[i]\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.set_title(f'Cluster {cluster_label}')\n",
    "    ax.axis('off')\n",
    "\n",
    "if len(cluster_labels) < len(axes):\n",
    "    fig.delaxes(axes[len(cluster_labels)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmeans-wordcloud.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
